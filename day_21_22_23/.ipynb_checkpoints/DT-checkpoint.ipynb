{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision tree algorithm is one of the most versatile algorithms in machine learning which can perform both classification and regression analysis. It is very powerful and works great with complex datasets. Apart from that, it is very easy to understand and read. That makes it more popular to use. When coupled with ensemble techniques – which we will learn very soon- it performs even better.\n",
    "As the name suggests, this algorithm works by dividing the whole dataset into a tree-like structure based on some rules and conditions and then gives prediction based on those conditions.\n",
    "Let’s understand the approach to decision tree with a basic scenario. \n",
    "Suppose it’s Friday night and you are not able to decide if you should go out or stay at home. Let the decision tree decide it for you.\n",
    "\n",
    "\n",
    "<img src=\"Decision_tree1.png\" width=\"300\">\n",
    "                         \n",
    "Although we may or may not use the decision tree for such decisions, this was a basic example to help you understand how a decision tree makes a decision.\n",
    "So how did it work?\n",
    "*\tIt selects a root node based on a given condition, e.g. our root node was chosen as time >10 pm.\n",
    "*\tThen, the root node was split into child notes based on the given condition. The right child node in the above figure fulfilled the condition, so no more questions were asked.\n",
    "*\tThe left child node didn’t fulfil the condition, so again it was split based on a new condition.\n",
    "*\tThis process continues till all the conditions are met or if you have predefined the depth of your tree, e.g. the depth of our tree is 3, and it reached there when all the conditions were exhausted.\n",
    "\n",
    "Let’s see how the parent nodes and condition is chosen for the splitting to work.\n",
    "\n",
    "#### Decision Tree for Regression\n",
    "When performing regression with a decision tree, we try to divide the given values of X into distinct and non-overlapping regions, e.g. for a set of possible values X1, X2,..., Xp; we will try to divide them into J distinct and non-overlapping regions R1, R2, . . . , RJ.\n",
    "For a given observation falling into the region Rj, the prediction is equal to the mean of the response(y) values for each training observations(x) in the region Rj. \n",
    "The regions R1,R2, . . . , RJ  are selected in a way to reduce the following sum of squares of residuals :\n",
    "\n",
    "\n",
    "<img src=\"formula1.png\" width=\"300\">\n",
    "                                                        \n",
    "Where, yrj (second term) is the mean of all the response variables in the region ‘j’.\n",
    "\n",
    "\n",
    "\n",
    "#### Recursive binary splitting(Greedy approach)\n",
    "As mentioned above, we try to divide the X values into j regions, but it is very expensive in terms of computational time to try to fit every set of X values into j regions. Thus, decision tree opts for a top-down greedy approach in which nodes are divided into two regions based on the given condition, i.e. not every node will be split but the ones which satisfy the condition are split into two branches. It is called greedy because it does the best split at a given step at that point of time rather than looking for splitting a step for a better tree in upcoming steps. It decides a threshold value(say s) to divide the observations into different regions(j) such that the RSS for Xj>= s and Xj <s is minimum.\n",
    "\n",
    "\n",
    "<img src=\"formula2.png\" width=\"400\">\n",
    "                      \n",
    "Here for the above equation, j and s are found such that this equation has the minimum value.\n",
    "The regions R1, R2 are selected based on that value of s and j such that the equation above has the minimum value.\n",
    "Similarly, more regions are split out of the regions created above based on some condition with the same logic. This continues until a stopping criterion (predefined) is achieved.\n",
    "Once all the regions are split, the prediction is made based on the mean of observations in that region.\n",
    "\n",
    "The process mentioned above has a high chance of overfitting the training data as it will be very complex. \n",
    "\n",
    "#### Tree Pruning\n",
    "Tree pruning is the method of trimming down a full tree (obtained through the above process) to reduce the complexity and variance in the data. Just as we regularised linear regression, we can also regularise the decision tree model by adding a new term. \n",
    "\n",
    "\n",
    "<img src=\"formula3.png\" width=\"300\">\n",
    "                                       \n",
    "Where, T  is the subtree which is a subset of the full tree T0\n",
    "And α is the non-negative tuning parameter which penalises the MSE with an increase in tree length.\n",
    "By using cross-validation, such values of α and T are selected for which our model gives the lowest test error rate.\n",
    "This is how the decision tree regression model works. Let’s now see the working algorithm of doing classification using a decision tree.\n",
    "Greedy Algorithm\n",
    "As per Hands-on machine learning book “greedy algorithm greedily searches for an optimum split at the top level, then repeats the process at each level. It does not check whether or not the split will lead to the lowest possible impurity several levels down. A greedy algorithm often produces a reasonably good solution, but it is not guaranteed to be the optimal solution.”\n",
    "\n",
    "\n",
    "#### Post-pruning\n",
    "\n",
    "Post-pruning, also known as backward pruning, is the process where the decision tree is generated first and then the non-significant branches are removed. Cross-validation set of data is used to check the effect of pruning and tests whether expanding a node will make an improvement or not. If any improvement is there then we continue by expanding that node else if there is reduction in accuracy then the node not be expanded and should be converted in a leaf node.\n",
    "\n",
    "\n",
    "#### Pre-pruning\n",
    "\n",
    "Pre-pruning, also known as forward pruning, stops the non-significant branches from generating. It uses a condition to decide when should it terminate splitting of some of the branches prematurely as the tree is generated. \n",
    "\n",
    "\n",
    "### Classification Trees\n",
    "\n",
    "Regression trees are used for quantitative data. In the case of qualitative data or categorical data, we use classification trees.  In regression trees, we split the nodes based on RSS criteria, but in classification, it is done using classification error rate, Gini impurity and entropy.\n",
    "Let’s understand these terms in detail.\n",
    "\n",
    "#### Entropy\n",
    "Entropy is the measure of randomness in the data. In other words, it gives the impurity present in the dataset.\n",
    "\n",
    "<img src=\"entropy.png\" width=\"300\">\n",
    "                                           \n",
    "When we split our nodes into two regions and put different observations in both the regions, the main goal is to reduce the entropy i.e. reduce the randomness in the region and divide our data cleanly than it was in the previous node. If splitting the node doesn’t lead into entropy reduction, we try to split based on a different condition, or we stop. \n",
    "A region is clean (low entropy) when it contains data with the same labels and random if there is a mixture of labels present (high entropy).\n",
    "Let’s suppose there are ‘m’ observations and we need to classify them into categories 1 and 2.\n",
    "Let’s say that category 1 has ‘n’ observations and category 2 has ‘m-n’ observations.\n",
    "\n",
    "p= n/m  and    q = m-n/m = 1-p\n",
    "\n",
    "then, entropy for the given set is:\n",
    "\n",
    "\n",
    "          E = -p*log2(p) – q*log2(q) \n",
    "           \n",
    "           \n",
    "When all the observations belong to category 1, then p = 1 and all observations belong to category 2, then p =0, int both cases E =0, as there is no randomness in the categories.\n",
    "If half of the observations are in category 1 and another half in category 2, then p =1/2 and q =1/2, and the entropy is maximum, E =1.\n",
    "\n",
    "\n",
    "<img src=\"entropy1.png\" width=\"600\">\n",
    "                                  \n",
    "\n",
    "#### Information Gain\n",
    "Information gain calculates the decrease in entropy after splitting a node. It is the difference between entropies before and after the split. The more the information gain, the more entropy is removed. \n",
    "\n",
    "<img src=\"info_gain.png\" width=\"300\">\n",
    "\n",
    "<center><h3>Information gain \n",
    "            G = 1 - sum((Sv/S)*E)</h3> e.g. Sv = Occurence of particular data ,S = Total occurence of that data, E = Entropy </center> \n",
    "                                 \n",
    "Where, T is the parent node before split and X is the split node from T.\n",
    "\n",
    "A tree which is splitted on basis of entropy and information gain value looks like:\n",
    "\n",
    "<img src=\"entropy_tree.png\" width=\"600\">\n",
    "\n",
    "#### Ginni Impurity\n",
    "According to wikipedia, ‘Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labelled if it was randomly labelled according to the distribution of labels in the subset.’\n",
    "It is calculated by multiplying the probability that a given observation is classified into the correct class and sum of all the probabilities when that particular observation is classified into the wrong class.\n",
    "Let’s suppose there are k number of classes and an observation belongs to the class ‘i’, then Ginni impurity is given as:\n",
    "\n",
    "<img src=\"ginni.png\" width=\"600\">\n",
    "\n",
    "\n",
    "Ginni impurity value lies between 0 and 1, 0 being no impurity and 1 denoting random distribution.\n",
    "The node for which the Ginni impurity is least is selected as the root node to split.\n",
    "\n",
    "\n",
    "A tree which is splitted on basis of ginni impurity value looks like:\n",
    "\n",
    "<img src=\"tree_example.png\" width=\"900\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maths behind Decision Tree Classifier\n",
    "\n",
    "We will use a simple dataset which contains information about students of different classes and gender and see whether they stay in school's hostel or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our data set looks like :\n",
    "\n",
    "\n",
    "<img src='data_class.PNG' width=\"200\">\n",
    "Let's try and understand how the root node is selected by calcualting gini impurity. We will use the above mentioned data.\n",
    "\n",
    "We have two features which we can use for nodes: \"Class\" and \"Gender\".\n",
    "We will calculate gini impurity for each of the features and then select that feature which has least gini impurity.\n",
    "\n",
    "Let's review the formula for calculating ginni impurity:\n",
    "\n",
    "<img src='example/gini.PNG' width=\"200\">\n",
    "\n",
    "Let's start with class, we will try to gini impurity for all different values in \"class\". \n",
    "\n",
    "<img src='example/1.png' width=\"500\">\n",
    "\n",
    "<img src='example/2.png' width=\"500\">\n",
    "\n",
    "<img src='example/3.1.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/3.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/4.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/5.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/6.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/7.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/8.PNG' width=\"500\">\n",
    "\n",
    "This is how our Decision tree node is selected by calculating gini impurity for each node individually.\n",
    "If the number of feautures increases, then we just need to repeat the same steps after the selection of the root node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try and find the root nodes for the same dataset by calculating entropy and information gain.\n",
    "\n",
    "DataSet:\n",
    "\n",
    "<img src='data_class.PNG' width=\"200\">\n",
    "\n",
    "We have two features and we will try to choose the root node by calculating the information gain by splitting each feature.\n",
    "\n",
    "Let' review the formula for entropy and information gain:\n",
    "\n",
    "<img src='example/formula_entropy.PNG' width=\"300\">\n",
    "\n",
    "<img src='example/inform_gain.PNG' width=\"300\">\n",
    "\n",
    "\n",
    "Let's start with feature \"class\" :\n",
    "\n",
    "<img src='example/9.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/10.1.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/11.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/12.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/13.PNG' width=\"500\">\n",
    "\n",
    "\n",
    "Let' see the information gain from feature \"gender\" :\n",
    "\n",
    "<img src='example/10.2.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/14.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/15.PNG' width=\"500\">\n",
    "\n",
    "<img src='example/16.PNG' width=\"500\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.198168</td>\n",
       "      <td>-0.174092</td>\n",
       "      <td>-1.099672</td>\n",
       "      <td>-1.587837</td>\n",
       "      <td>-1.536196</td>\n",
       "      <td>-1.571129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.240361</td>\n",
       "      <td>-1.360738</td>\n",
       "      <td>1.585529</td>\n",
       "      <td>-1.641325</td>\n",
       "      <td>-1.658774</td>\n",
       "      <td>-1.741175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.198168</td>\n",
       "      <td>-3.385019</td>\n",
       "      <td>3.375663</td>\n",
       "      <td>-1.498691</td>\n",
       "      <td>-1.457395</td>\n",
       "      <td>-1.741175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.071587</td>\n",
       "      <td>0.454133</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>-1.364971</td>\n",
       "      <td>-1.317305</td>\n",
       "      <td>-1.287720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.029394</td>\n",
       "      <td>1.082358</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>-1.240167</td>\n",
       "      <td>-1.212238</td>\n",
       "      <td>-1.117674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat     depth     table         x         y         z  Good  Ideal  \\\n",
       "0 -1.198168 -0.174092 -1.099672 -1.587837 -1.536196 -1.571129     0      1   \n",
       "1 -1.240361 -1.360738  1.585529 -1.641325 -1.658774 -1.741175     0      0   \n",
       "2 -1.198168 -3.385019  3.375663 -1.498691 -1.457395 -1.741175     1      0   \n",
       "3 -1.071587  0.454133  0.242928 -1.364971 -1.317305 -1.287720     0      0   \n",
       "4 -1.029394  1.082358  0.242928 -1.240167 -1.212238 -1.117674     1      0   \n",
       "\n",
       "   Premium  Very Good  ...  I  J  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  price  \n",
       "0        0          0  ...  0  0   0    0    1    0    0     0     0    326  \n",
       "1        1          0  ...  0  0   0    1    0    0    0     0     0    326  \n",
       "2        0          0  ...  0  0   0    0    0    1    0     0     0    327  \n",
       "3        1          0  ...  1  0   0    0    0    0    1     0     0    334  \n",
       "4        0          0  ...  0  1   0    0    1    0    0     0     0    335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ML_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price'],axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Very Good</th>\n",
       "      <th>...</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.198168</td>\n",
       "      <td>-0.174092</td>\n",
       "      <td>-1.099672</td>\n",
       "      <td>-1.587837</td>\n",
       "      <td>-1.536196</td>\n",
       "      <td>-1.571129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.240361</td>\n",
       "      <td>-1.360738</td>\n",
       "      <td>1.585529</td>\n",
       "      <td>-1.641325</td>\n",
       "      <td>-1.658774</td>\n",
       "      <td>-1.741175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.198168</td>\n",
       "      <td>-3.385019</td>\n",
       "      <td>3.375663</td>\n",
       "      <td>-1.498691</td>\n",
       "      <td>-1.457395</td>\n",
       "      <td>-1.741175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.071587</td>\n",
       "      <td>0.454133</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>-1.364971</td>\n",
       "      <td>-1.317305</td>\n",
       "      <td>-1.287720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.029394</td>\n",
       "      <td>1.082358</td>\n",
       "      <td>0.242928</td>\n",
       "      <td>-1.240167</td>\n",
       "      <td>-1.212238</td>\n",
       "      <td>-1.117674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat     depth     table         x         y         z  Good  Ideal  \\\n",
       "0 -1.198168 -0.174092 -1.099672 -1.587837 -1.536196 -1.571129     0      1   \n",
       "1 -1.240361 -1.360738  1.585529 -1.641325 -1.658774 -1.741175     0      0   \n",
       "2 -1.198168 -3.385019  3.375663 -1.498691 -1.457395 -1.741175     1      0   \n",
       "3 -1.071587  0.454133  0.242928 -1.364971 -1.317305 -1.287720     0      0   \n",
       "4 -1.029394  1.082358  0.242928 -1.240167 -1.212238 -1.117674     1      0   \n",
       "\n",
       "   Premium  Very Good  ...  H  I  J  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  \n",
       "0        0          0  ...  0  0  0   0    0    1    0    0     0     0  \n",
       "1        1          0  ...  0  0  0   0    1    0    0    0     0     0  \n",
       "2        0          0  ...  0  0  0   0    0    0    1    0     0     0  \n",
       "3        1          0  ...  0  1  0   0    0    0    0    1     0     0  \n",
       "4        0          0  ...  0  0  1   0    0    1    0    0     0     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    326\n",
       "1    326\n",
       "2    327\n",
       "3    334\n",
       "4    335\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor,export_graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999956833593837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557440654854801"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Analysis on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(x_train)\n",
    "residual = y_train - y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price', ylabel='Density'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15745.,  2482., 11927., ...,   926.,  4991.,   624.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual Analysis on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price', ylabel='Density'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'max_depth':range(2,32,1),\n",
    "    'min_samples_leaf':range(1,10,1),\n",
    "    'min_samples_split':range(2,10,1),\n",
    "    'splitter': ['best','random'],\n",
    "    'max_features':['auto','sqrt','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['mse', 'friedman_mse',\n",
       "                                                      'mae', 'poisson'],\n",
       "                                        'max_depth': range(2, 32),\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': range(1, 10),\n",
       "                                        'min_samples_split': range(2, 10),\n",
       "                                        'splitter': ['best', 'random']},\n",
       "                   random_state=33, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(estimator=clf,param_distributions=grid_params,n_iter=100,cv=5,verbose=2,n_jobs=-1,random_state=33)\n",
    "rand_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitter': 'random',\n",
       " 'min_samples_split': 7,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 19,\n",
       " 'criterion': 'mse'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=19, max_features='auto', min_samples_leaf=5,\n",
       "                      min_samples_split=7, splitter='random')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random_grid = rand_search.best_estimator_\n",
    "best_random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17040.22222222,  2472.        , 11744.71428571, ...,\n",
       "         980.2962963 ,  5115.81756757,   626.66666667])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_random_grid.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981346666144476"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9675718174085508"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-cb3d064a2052>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-cb3d064a2052>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    residual =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "residual = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
